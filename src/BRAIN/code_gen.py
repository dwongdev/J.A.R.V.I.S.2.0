import logging
import os
import pandas as pd
import re
from langchain_ollama import ChatOllama
from src.FUNCTION.get_env import load_variable
from src.FUNCTION.code_exec import execute_code_with_dependencies
from google import genai


# Configure logging (do this once at the beginning of your script)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(module)s - %(message)s')
logger = logging.getLogger(__name__)

def provide_file_details(path: str) -> str:
    logger.info(f"Providing details for file: {path}")
    try:
        df = pd.read_csv(path)
        details = [
            f"File Path: {path}",
            f"File Size: {df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB",
            f"Shape (rows, columns): {df.shape}",
            f"Column Names: {df.columns.tolist()}",
            f"Data Types:\n{df.dtypes.to_string()}",
            f"First 5 rows:\n{df.head().to_string(index=False)}",
            f"Missing values:\n{df.isnull().sum().to_string()}",
            f"Summary statistics:\n{df.describe(include='all').to_string()}",
            f"Unique values per column:\n{df.nunique().to_string()}",
            f"Sample value types per column:\n{df.iloc[0].to_dict()}"
        ]
        return "\n\n".join(details)
    except FileNotFoundError:
        logger.error(f"File not found at path: {path}")
        return ""
    except Exception as e:
        logger.error(f"Error while processing file {path}: {e}", exc_info=True) # Log with traceback
        return ""

def extract_python_code(text):
    pattern = r"```python\s*(.*?)\s*```"
    match = re.search(pattern, text, re.DOTALL)
    if match:
        code = match.group(1).strip()
        logger.debug(f"Extracted Python code:\n{code}")
        return code
    else:
        logger.info("No Python code found in the text.")
        return ""

def generate_refactor_prompt(code: str, error: str, file_description: str):
    """
    Generate a comprehensive prompt for a code refactoring assistant to analyze the code and refactor it.

    Args:
        code (str): The Python code that generated the error.
        error (str): The error message generated by the code.
        file_description (str): The detailed description of the file being used in the code.

    Returns:
        str: A detailed prompt for refactoring the code.
    """
    full_prompt = f"""
    You are an expert Python code refactor assistant. The user has provided code that generated an error during execution.
    The task is to analyze the code and the accompanying error, then refactor the code to resolve the issue.
    The code uses standard Python libraries such as pandas, numpy, and matplotlib, and works with the following file.

    File Description:
    {file_description}

    The Python code provided is as follows:

    Code:
    {code}

    The error generated is:

    Error:
    {error}

    Instructions:
    - Thoroughly examine the provided code and understand its logic.
    - Investigate the error message and identify the root cause.
    - Refactor the code to fix the error, making it syntactically correct and functional.
    - Ensure that the code properly utilizes the libraries (pandas, numpy, matplotlib) and their functionalities.
    - If the error relates to file handling (e.g., file not found or data loading issues), ensure the code correctly handles file paths and errors.
    - Check for common pitfalls such as incorrect file paths, missing libraries, or improperly used functions.
    - After refactoring, ensure that the code works as expected and generates the correct output without errors.

    Your goal is to refine the code to make it error-free, maintainable, and functional. Pay special attention to the correct use of libraries and error handling.
    """
    logger.debug(f"Generated refactor prompt:\n{full_prompt}")
    return full_prompt

def gem_refactor_code(first_response_code: str, attempt: int = 1, max_attempts: int = 3):
    logger.info(f"Attempting to refactor code (attempt {attempt}/{max_attempts})")
    if not first_response_code:
        logger.warning("No code provided for refactoring.")
        return {"error": "No code generated."}

    exec_info = execute_code_with_dependencies(first_response_code)
    logger.info(f"Code execution result (attempt {attempt}): {exec_info}")
    
    if exec_info.get("error"):
        ERROR = exec_info.get("error")
        logger.error(f"Code execution error (attempt {attempt}): {ERROR}")
        if attempt >= max_attempts:
            logger.error(f"Max refactor attempts reached. Last error: {ERROR}")
            return {"error": f"Max attempts reached. Last error: {ERROR}"}

        file_path = load_variable("CSV_PATH")
        file_description = provide_file_details(file_path)
        full_prompt = generate_refactor_prompt(first_response_code, ERROR, file_description)

        api_key = load_variable("genai_key")
        try:
            client = genai.Client(api_key=api_key)
            logger.info("Calling Gemini API for code refactoring.")
            response_code = client.models.generate_content(
                model='gemini-2.0-flash',
                contents=full_prompt
            )
            refactored_code = extract_python_code(response_code.text)
            logger.info(f"Received refactored code from Gemini (attempt {attempt}):\n{refactored_code}")
            return gem_refactor_code(refactored_code, attempt + 1, max_attempts)
        except Exception as e:
            logger.error(f"Error during Gemini API call (attempt {attempt}): {e}", exc_info=True)
            return {"error": f"Error during Gemini API call: {e}"}

    logger.info(f"Code executed successfully after {attempt} attempt(s).")
    return exec_info

def gem_text_to_code(user_prompt: str):
    logger.info(f"Generating code from user prompt using Gemini: '{user_prompt}'")
    api_key = load_variable("genai_key")
    client = genai.Client(api_key=api_key)

    file_path = load_variable("CSV_PATH")
    if not os.path.exists(file_path):
        logger.error(f"CSV file not found at path: {file_path}")
        raise FileNotFoundError(f"{file_path} not found!.")

    file_description = provide_file_details(file_path)
    full_prompt = f"""
    You are a Python data analysis assistant. The user has provided a CSV file at path: '{file_path}'.

    Use standard Python libraries like pandas, numpy, and matplotlib where needed.
    Use the following information about the file:
    {file_description}

    User Query: {user_prompt}

    Generate the correct code using the CSV path and context. Make sure it’s syntactically valid and relevant.
    """
    logger.debug(f"Generated Gemini prompt for text-to-code:\n{full_prompt}")

    try:
        logger.info("Calling Gemini API for text-to-code.")
        response_code = client.models.generate_content(
            model='gemini-2.0-flash',
            contents=full_prompt
        )
        generated_code = extract_python_code(response_code.text)
        if generated_code:
            logger.info("Generated Python code from Gemini.")
            exec_info = gem_refactor_code(generated_code)
            return exec_info
        else:
            logger.warning("Gemini did not generate any executable Python code.")
            return None
    except Exception as e:
        logger.error(f"Error during Gemini API call for text-to-code: {e}", exc_info=True)
        return None

def local_refactor_code(first_response_code: str, attempt: int = 1, max_attempts: int = 10):
    logger.info(f"Attempting to locally refactor code (attempt {attempt}/{max_attempts})")
    if not first_response_code:
        logger.warning("No code provided for local refactoring.")
        return {"error": "No code generated."}

    exec_info = execute_code_with_dependencies(first_response_code)
    logger.info(f"Local code execution result (attempt {attempt}): {exec_info}")

    if exec_info.get('error'):
        ERROR = exec_info.get("error")
        logger.error(f"Local code execution error (attempt {attempt}): {ERROR}")
        if attempt >= max_attempts:
            logger.error(f"Max local refactor attempts reached. Last error: {ERROR}")
            return {"error": f"Max attempts reached. Last error: {ERROR}"}

        file_path = load_variable("CSV_PATH")
        file_description = provide_file_details(file_path)
        full_prompt = generate_refactor_prompt(first_response_code, ERROR, file_description)

        model = load_variable("Text_to_info_model")
        try:
            llm = ChatOllama(
                model=model,
                temperature=0.3,
            )
            messages = [
                {"role": "system", "content": full_prompt},
                {"role": "user", "content": first_response_code}
            ]
            logger.info("Calling local LLM (Ollama) for code refactoring.")
            response_code = llm.invoke(messages)
            refactored_code = extract_python_code(response_code)
            logger.info(f"Received refactored code from local LLM (attempt {attempt}):\n{refactored_code}")
            return local_refactor_code(refactored_code, attempt + 1, max_attempts)
        except Exception as e:
            logger.error(f"Error during local LLM invocation (attempt {attempt}): {e}", exc_info=True)
            return {"error": f"Error during LLM invocation: {str(e)}"}

    logger.info(f"Local code executed successfully after {attempt} attempt(s).")
    return exec_info

def local_text_code(user_prompt: str):
    logger.info(f"Generating code from user prompt using local LLM: '{user_prompt}'")
    model = load_variable("Text_to_info_model")

    file_path = load_variable("CSV_PATH")
    file_description = provide_file_details(file_path)
    full_prompt = f"""
    You are a Python data analysis assistant. The user has provided a CSV file at path: '{file_path}'.

    Use standard Python libraries like pandas, numpy, and matplotlib where needed.
    Use the following information about the file:
    {file_description}

    Generate the correct code using the CSV path and context. Make sure it’s syntactically valid and relevant.
    """
    logger.debug(f"Generated local LLM prompt for text-to-code:\n{full_prompt}")

    try:
        llm = ChatOllama(
            model=model,
            temperature=0.3,
        )
        messages = [
            {"role": "system", "content": full_prompt},
            {"role": "user", "content": user_prompt}
        ]
        logger.info("Calling local LLM (Ollama) for text-to-code.")
        response_code = llm.invoke(messages)
        generated_code = extract_python_code(response_code)
        if generated_code:
            logger.info("Generated Python code from local LLM.")
            exec_info = local_refactor_code(generated_code)
            return exec_info
        else:
            logger.warning("Local LLM did not generate any executable Python code.")
            return None
    except Exception as e:
        logger.error(f"Error during local LLM invocation for text-to-code: {e}", exc_info=True)
        return None
    
def data_analysis(user_prompt: str):
    try:
        # Try to generate code via API
        response = gem_text_to_code(user_prompt)
        
    except Exception as e:
        # If API fails, log the error and fall back to local code generation
        logger.error(f"ERROR: {e} - Falling back to local processing.")
        response = local_text_code(user_prompt)
    return response
